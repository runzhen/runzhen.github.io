<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Lsm on Mind in the Wind</title>
    <link>https://runzhen.github.io/tags/lsm/</link>
    <description>Recent content in Lsm on Mind in the Wind</description>
    <image>
      <title>Mind in the Wind</title>
      <url>https://runzhen.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://runzhen.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.145.0</generator>
    <language>en</language>
    <lastBuildDate>Sun, 09 Jun 2019 00:33:33 -0700</lastBuildDate>
    <atom:link href="https://runzhen.github.io/tags/lsm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LSM Tree 简介</title>
      <link>https://runzhen.github.io/posts/lsm-tree-basic/</link>
      <pubDate>Sun, 09 Jun 2019 00:33:33 -0700</pubDate>
      <guid>https://runzhen.github.io/posts/lsm-tree-basic/</guid>
      <description>&lt;p&gt;LSM Tree 是 Log Structured Merge Tree 的缩写，这种 Tree 数据结构的特点就是”Log Structured“ 和 ”Merge“。LSM Tree 主要用在各种新兴的数据库，作为底层数据结构。 提供了比 B+ 树/ISAM 更好的写性能。&lt;/p&gt;
&lt;p&gt;本文是一篇读书笔记，作为以后再次阅读的提纲，此外，原文旁征博引有不少参考资料，值得一读。 &lt;a href=&#34;http://www.benstopford.com/2015/02/14/log-structured-merge-trees/&#34;&gt;原文传送门&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;some-background&#34;&gt;Some Background&lt;/h2&gt;
&lt;p&gt;核心： 硬盘（无论是磁盘，SSD 甚至是内存）随机读写性能太差，但是顺序读写性能非常高，所以要充分利用一点。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://queue.acm.org/detail.cfm?id=1563874&#34;&gt;这篇文章&lt;/a&gt;指出，磁盘的顺序访问甚至比内存的随机访问还快！&lt;/p&gt;
&lt;p&gt;所以，如果我们对写性能要求高，怎么办？ 一种方法是写数据的时候只 append（添加在文件尾部）。通常我们把这种叫做写日志，logging。&lt;/p&gt;
&lt;p&gt;但是，简单的 log 结构无法满足复杂的需求，为了满足类似搜索、kv 之类的场景，需要在 logging 基础上加上额外的数据结构，比如 binary search, hash, B+ or external。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Search Sorted File: save data to a file, sorted by key. If data has defined widths use Binary search. If not use a page index + scan.&lt;/li&gt;
&lt;li&gt;Hash: split the data into buckets using a hash function, which can later be used to direct reads.&lt;/li&gt;
&lt;li&gt;B+: use navigable file organisation such as a B+ tree, ISAM etc.&lt;/li&gt;
&lt;li&gt;External file: leave the data as a log/heap and create a separate hash or tree index into it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上 4 种方法都可以改善读性能。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
