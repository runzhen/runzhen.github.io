<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Concurrency on Mind in the Wind</title>
    <link>https://runzhen.github.io/tags/concurrency/</link>
    <description>Recent content in Concurrency on Mind in the Wind</description>
    <image>
      <title>Mind in the Wind</title>
      <url>https://runzhen.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://runzhen.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.125.5</generator>
    <language>en</language>
    <lastBuildDate>Tue, 13 Oct 2020 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://runzhen.github.io/tags/concurrency/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Goroutine Pool 实现高并发</title>
      <link>https://runzhen.github.io/posts/goroutine-pool/</link>
      <pubDate>Tue, 13 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://runzhen.github.io/posts/goroutine-pool/</guid>
      <description>本文是读完 Handling 1 Million Requests per Minute with Go 之后，根据自己的理解，对文中提到的并发模型和实现再梳理一遍。
前言 假设有一个 http server 接收 client 发来的 request，如果用下面的这样的代码，会有什么问题呢？
func payloadHandler(w http.ResponseWriter, r *http.Request) { // Go through each payload and queue items individually to be posted to S3 for _, payload := range content.Payloads { go payload.UploadToS3() // &amp;lt;----- DON&amp;#39;T DO THIS } } 显而易见，有 2 个问题：
接收一个 request 就开启一个 goroutine 处理，当 request 数量在短时间内暴增的话，光是 goroutine 的数量都足以让 server 崩溃。 每个 goroutine 都会与后端建立 TCP 连接，既耗费三次握手的时间，也会造成后端有大量 TCP 连接 所以，我们的目标是 没有蛀牙</description>
    </item>
  </channel>
</rss>
